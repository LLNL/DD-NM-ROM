{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map ports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "with open(\"./../../PATHS.txt\") as file:\n",
    "  paths = file.read().splitlines()\n",
    "sys.path.extend(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from dd_nm_rom import backend as bkd\n",
    "from dd_nm_rom.ops import map_nested_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_models = \"/Users/zanardi1/Workspace/Codes/DD-NM-ROM/run/data/trained_nets/nx_480_ny_24_mu_0.1_2x_by_2y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG(object):\n",
    "\n",
    "  def __init__(self, cfg) -> None:\n",
    "    for k, v in cfg.items():\n",
    "      setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {\n",
    "#   'encoder': self.best_encoder,\n",
    "#   'decoder': self.best_decoder,\n",
    "#   'mask': self.mask,\n",
    "#   'scale': self.scale,\n",
    "#   'ref': self.ref,\n",
    "#   'input_dim': self.input_dim,\n",
    "#   'latent_dim': self.latent_dim,\n",
    "#   'output_dim': self.output_dim,\n",
    "#   'encoder_hidden': self.encoder_hidden,\n",
    "#   'decoder_hidden': self.decoder_hidden,\n",
    "#   'act_type': self.act_type,\n",
    "#   'train_time': train_time,\n",
    "#   'epoch': epoch,\n",
    "#   'early_stop_counter': early_stop_counter,\n",
    "#   'valid_loss_hist': valid_loss_hist,\n",
    "#   'train_loss_hist': train_loss_hist,\n",
    "#   'best_test_loss': best_test_loss,\n",
    "#   'best_train_loss': best_train_loss,\n",
    "#   'best_loss_epoch': best_loss_epoch\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(cfg):\n",
    "  config_common = {\n",
    "    \"ref\": bkd.to_numpy(cfg.ref).reshape(-1),\n",
    "    \"scale\": bkd.to_numpy(cfg.scale).reshape(-1),\n",
    "    \"input_dim\": int(cfg.input_dim),\n",
    "    \"latent_dim\": int(cfg.latent_dim),\n",
    "    \"activation\": str(cfg.act_type).lower()\n",
    "  }\n",
    "  config = {}\n",
    "  for l in (\"encoder\", \"decoder\"):\n",
    "    hidden = cfg.decoder_hidden if (l == \"decoder\") else cfg.encoder_hidden\n",
    "    layer = cfg.decoder if (l == \"decoder\") else cfg.encoder\n",
    "    mask = cfg.mask if (l == \"decoder\") else cfg.mask.T\n",
    "    mask_shape = tuple(mask.shape)\n",
    "    config[l] = {\n",
    "      \"weights\": get_weights_np(layer, mask_shape),\n",
    "      \"mask_shape\": mask_shape,\n",
    "      \"mask_indices\": np.vstack(mask.nonzero()),\n",
    "      \"hidden_dim\": hidden\n",
    "    }\n",
    "    config[l].update(config_common)\n",
    "  return config\n",
    "\n",
    "def get_weights_np(weights, mask_shape):\n",
    "  weights = map_nested_dict(weights, bkd.to_numpy)\n",
    "  weights_np = {}\n",
    "  for (i, k) in enumerate((0,2)):\n",
    "    if (f'net.{k}.indices' in weights):\n",
    "      mask = tuple([weights[f'net.{k}.indices'][j] for j in range(2)])\n",
    "      wi = sp.csr_matrix(\n",
    "        (weights[f'net.{k}.weights'], mask), shape=mask_shape\n",
    "      )\n",
    "    else:\n",
    "      wi = weights[f'net.{k}.weight']\n",
    "    weights_np[f\"W{i+1}\"] = wi\n",
    "  weights_np[\"b1\"] = weights['net.0.bias']\n",
    "  return weights_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(path_to_models):\n",
    "  for file in files:\n",
    "    filename = os.path.join(subdir, file)\n",
    "    if (\"numpy\" in filename):\n",
    "      continue\n",
    "    cfg = torch.load(filename, map_location=\"cpu\")\n",
    "    cfg_np = convert(CFG(cfg))\n",
    "    torch.save(cfg_np, filename[:-2]+\"_numpy.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from sparselinear import SparseLinear\n",
    "import scipy as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Linear(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x\n",
    "\n",
    "class Identity(torch.nn.Module):\n",
    "  '''\n",
    "  Generic class for decoder part of autoencoder.\n",
    "  The struture is shallow with one hidden layer.\n",
    "\n",
    "  inputs:\n",
    "  latent_dim: dimension of latent dimension\n",
    "  hidden_dim: dimension of linear hidden layer\n",
    "  output_dim: dimension of outputs\n",
    "  mask:       sparsity mask in coo format\n",
    "  scale:      (output_dim) tensor for scaling input data\n",
    "  ref:        (output_dim) tensor for shifting input data\n",
    "  activation: [optional] activation function between hidden and output layer. 'Swish' or 'Sigmoid'. Default is 'Sigmoid'\n",
    "  '''\n",
    "  def __init__(self, dim, scale, ref):\n",
    "    super(Identity, self).__init__()\n",
    "    self.dim = dim\n",
    "    self.ref = ref\n",
    "    self.scale = scale\n",
    "    mask = sp.sparse.identity(self.dim).tocoo()\n",
    "    lay = SparseLinear(dim, dim, connectivity=torch.LongTensor(np.vstack((mask.row, mask.col))), bias=False)\n",
    "    self.net = torch.nn.Sequential(lay, Linear(), lay)\n",
    "    self.net.apply(self.init_weights)\n",
    "\n",
    "  def init_weights(self, m):\n",
    "    if isinstance(m, SparseLinear):\n",
    "      torch.nn.init.ones_(m.weights)\n",
    "      if m.bias is not None:\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "  '''\n",
    "  Generic class for decoder part of autoencoder.\n",
    "  The struture is shallow with one hidden layer.\n",
    "\n",
    "  inputs:\n",
    "  latent_dim: dimension of latent dimension\n",
    "  hidden_dim: dimension of linear hidden layer\n",
    "  output_dim: dimension of outputs\n",
    "  mask:       sparsity mask in coo format\n",
    "  scale:      (output_dim) tensor for scaling input data\n",
    "  ref:        (output_dim) tensor for shifting input data\n",
    "  activation: [optional] activation function between hidden and output layer. 'Swish' or 'Sigmoid'. Default is 'Sigmoid'\n",
    "  '''\n",
    "  def __init__(self, latent_dim, hidden_dim, output_dim, mask,\n",
    "         scale, ref,\n",
    "         act_fun=torch.nn.Sigmoid):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.scale = scale\n",
    "    self.ref = ref\n",
    "    self.net = torch.nn.Sequential(\n",
    "      SparseLinear(hidden_dim, output_dim, connectivity=torch.LongTensor(np.vstack((mask.row, mask.col))), bias=False),\n",
    "      act_fun(),\n",
    "      SparseLinear(hidden_dim, output_dim, connectivity=torch.LongTensor(np.vstack((mask.row, mask.col))), bias=False)\n",
    "    )\n",
    "    self.net.apply(self.init_weights)\n",
    "\n",
    "  def init_weights(self, m):\n",
    "    if isinstance(m, SparseLinear):\n",
    "      torch.nn.init.ones_(m.weights)\n",
    "      if m.bias is not None:\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "  def forward(self, w):\n",
    "    return self.net((w-self.ref)/self.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weights', tensor([1., 1.])),\n",
       "             ('net.0.indices',\n",
       "              tensor([[0, 1],\n",
       "                      [0, 1]])),\n",
       "             ('net.2.weights', tensor([1., 1.])),\n",
       "             ('net.2.indices',\n",
       "              tensor([[0, 1],\n",
       "                      [0, 1]]))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "hidden_dim = 2\n",
    "output_dim = 2\n",
    "mask = sp.sparse.identity(2).tocoo()\n",
    "ref = torch.rand(2)\n",
    "scale = torch.rand(2)\n",
    "\n",
    "iden = Identity(latent_dim, scale, ref)\n",
    "\n",
    "iden.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
